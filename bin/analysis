#!/usr/bin/env python

import os
import os.path as osp
import json
import click


from euphemism.util import preprocess_path



ROOT = osp.abspath(osp.join(osp.dirname(osp.abspath(__file__)), '..'))
DATA_ROOT = osp.join(ROOT, 'data')


@click.command()
@click.option(
    '--data-file',
    type=click.Path(exists=True, file_okay=True), 
    default=osp.join(DATA_ROOT, 'train.json'),
)
@click.option(
    '--answers-file',
    type=click.Path(exists=True, file_okay=True),
)
@click.option(
    '--terms-file',
    type=click.Path(exists=True, file_okay=True),
    default=osp.join(DATA_ROOT, 'terms.tsv'),
)
@click.option(
    '--term',
    type=str,
    default='regime change',
)
def main(data_file, answers_file, terms_file, term):
    data_file = preprocess_path(data_file)
    answers_file = preprocess_path(answers_file)
    terms_file = preprocess_path(terms_file)

    with open(data_file, 'r') as f:
        data = json.load(f)

    with open(answers_file, 'r') as f:
        for line in f.readlines():
            l = line.strip().split(',')
            if len(l) != 2:
                continue
            idx, label = int(l[0]), int(l[1])
            data[idx]['answer'] = label

    terms = dict()
    with open(terms_file, 'r') as f:
        for line in f.readlines()[1:]:
            l = line.strip().split('\t')
            if len(l) != 2:
                continue
            term, defn = l[0], l[1]
            terms[term] = defn

    # count
    TPs, TNs, FPs, FNs = {}, {}, {}, {}
    for item in data:
        term = item['lemmatized']
        if item['label'] == 1 and item['answer'] == 1:
            TPs[term] = 1+TPs.get(term, 0)
        elif item['label'] == 0 and item['answer'] == 0:
            TNs[term] = 1+TNs.get(term, 0)
        elif item['label'] == 0 and item['answer'] == 1:
            FPs[term] = 1+FPs.get(term, 0)
        elif item['label'] == 1 and item['answer'] == 0:
            FNs[term] = 1+FNs.get(term, 0)
    
    results = []
    for term in terms.keys():
        PP = TPs.get(term, 0) + FPs.get(term, 0)
        prec = 0.0
        if PP > 0:
            prec = round(100 * TPs.get(term, 0) // PP, 2)
        
        rec = 0.0
        P = TPs.get(term, 0) + FNs.get(term, 0)
        if P > 0:
            rec = round(100 * TPs.get(term, 0) // P, 2)

        F1 = 0.0
        if (prec + rec) > 0:
            F1 = round((2*(prec * rec)) / (prec + rec), 2)
        
        N = PP + FNs.get(term, 0) + TNs.get(term, 0)
        if N > 0:
            results.append((term, prec, rec, F1, N))
    results.sort(key=lambda x: x[3])

    for k, p, r, F1, N in results:
        defn = terms[k]
        print(f'p = {p}, r = {r}, f1 = {F1} \t count: {N} term: {k}. defn = {defn}')


    subset = [x for x in data if x['lemmatized'] == term]
    fps, fns = [], []
    for x in subset:
        if x['label'] == 0 and x['answer'] == 1:
            fps.append(x)
        if x['label'] == 1 and x['answer'] == 0:
            fns.append(x)
    
    print('\n\n')
    print('FALSE POSITIVES')
    for x in fps:
        print(f'-- idx: {x["index"]}, text: {x["utterance"]}')

    print('\n\n')
    print('FALSE NEGATIVES')
    for x in fns:
        print(f'-- idx: {x["index"]}, text: {x["utterance"]}')
    


if __name__ == "__main__":
    main()